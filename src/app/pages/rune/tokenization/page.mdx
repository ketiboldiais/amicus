import MdxLayout from "@/components/mdx-layout";

import {TANGENT_LINE} from "@/components/Calculus"

# Tokenization

<TOC>

- [Introduction](#introduction)
- [Tokens](#tokens)
  - [Utility Token Types](#utility-token-types)
  - [Paired Delimiters](#paired-delimiters)
  - [Unary Delimiters](#unary-delimiters)
  - [Algebraic Operators](#algebraic-operators)
  - [Relational Operators](#relational-operators)
  - [Assignment Operator](#assignment-operator)
  - [Tickers](#tickers)
  - [List Operators](#list-operators)
  - [Vector Operators](#vector-operators)
  - [Matrix Operators](#matrix-operators)
  - [Literals](#literals)
  - [Keywords](#keywords)
- [Scanning](#scanning)

</TOC>

## Introduction
Before we begin implementing, we start with some definitions up front. First, the formal definition of a __symbol__: 

> __*definition*__. A _symbol_, or a _token_, is an atomic unit that a machine can read and write.


For example: ${1,}$ ${\pi,}$ ${\Sigma,}$ ${0,}$ ${x,}$ ${y,}$ ${f,}$ are all symbols. If your computer can highlight it with its cursor—that's almost certainly a symbol, or token. If we put these symbols in a box, we call that box an __alphabet__.  

> __*definition*__. An _alphabet_ is a nonempty and finite set of symbols.

A generic alphabet is often denoted with the Greek letter ${\Sigma.}$

Since symbols are discrete things, we can distinguish between them, which allows us to place them in nice, clear sequences. We call such sequences __strings__.

> __*definition*__. A _string_ over an alphabet is a sequence of symbols from that alphabet.

A generic string is often denoted with the Greek letters ${\sigma}$ or ${\tau.}$ We use the Greek letter ${\varepsilon}$ to denote the empty string—a sequence of symbols of zero length.  The set of all strings over an alphabet ${\Sigma}$ is denoted ${\Sigma^{*}.}$

If we take a bunch of strings and put them in a box, we get a __language__.

> __*definition*__. A _language_ ${L}$ over an alphabet ${\Sigma}$ is a set of strings drawn from ${\Sigma.}$ That is, ${L \subseteq \Sigma^{*}.}$

Keep in mind that this is what a language is from a computer science perspective—it's just a set of strings over a specified alphabet.

## Tokens
Now that we know what a token is, let's start by specifying the tokens we want our language, Rune, to recognize.

We make a distinction between _tokens_ and _token types_. The digits ${1,}$ ${2,}$ ${3,}$ and so on, are all _tokens_. We could read each of these tokens one at a time, but it's clear that certain sequences of tokens (_strings_) are always going to be interpreter the same way. For example, the string ${1393}$ is always an _integer_. Likewise, the string `"while"` is always the keyword `"while"`, which we interpret as marking an iteration procedure.  

Below are all the token types Rune recognizes. Within Rune's source code, these are implemented with a TypeScript enum.

### Utility Token Types
The following token types are used as flags. When encountered during tokenization or parsing, they tell us that something went wrong, and we should halt all further work. 

| Token Type | Lexeme              | Flag                                    |
| ---------- | ------------------- | --------------------------------------- |
| `end`      | `""` (empty string) | End of source code reached.             |
| `error`    | `""` (empty string) | A scanning error occurred.              |
| `empty`    | `""` (empty string) | The empty token, used as a placeholder. |

### Paired Delimiters
These are token types that always come in pairs. For example, the opening parenthesis `"("` and its counterpart, the closing `")"`. If our tokenizer or parser encounters one of these tokens, then we should expect to see its other half.  

| Token Type      | Lexeme |
| --------------- | ------ |
| `left_paren`    | `"("`  |
| `right_paren`   | `")"`  |
| `left_brace`    | `"{"`  |
| `right_brace`   | `"}"`  |
| `left_bracket`  | `"["`  |
| `right_bracket` | `"]"`  |

### Unary Delimiters
Unary delimiters are single, stand-alone token types. They are akin to punctuation—signals that something else follows or precedes, chopping up long token streams into bite-sized, easier-to-digest chunks.

| Token Type  | Lexeme |
| ----------- | ------ |
| `semicolon` | `";"`  |
| `colon`     | `":"`  |
| `dot`       | `"."`  |
| `comma`     | `","`  |

### Algebraic Operators
These token types correspond to algebraic operations. 

| Token Type | Lexeme |
| ---------- | ------ |
| `plus`     | `"+"`  |
| `minus`    | `"-"`  |
| `star`     | `"*"`  |
| `slash`    | `"/"`  |
| `caret`    | `"^"`  |
| `percent`  | `"%"`  |
| `bang`     | `"!"`  |

### Relational Operators
These token types correspond to relation operations.

| Token Type      | Lexeme |
| --------------- | ------ |
| `vbar`          | `"\|"` |
| `tilde`         | `"~"`  |
| `equal`         | `"="`  |
| `less`          | `"<"`  |
| `greater`       | `">"`  |
| `less_equal`    | `"<="` |
| `greater_equal` | `">="` |
| `bang_equal`    | `"!="` |
| `equal_equal`   | `"=="` |

### Assignment Operator
This token type corresponds to _assignment_ or _definition_.

| Token Type    | Lexeme |
| ------------- | ------ |
| `colon_equal` | `":="` |

### Tickers
These token types correspond to increment- and decrement-assign.

| Token Type    | Lexeme |
| ------------- | ------ |
| `plus_plus`   | `"++"` |
| `minus_minus` | `"--"` |

### List Operators
These token types correspond to list operations.

| Token Type  | Lexeme |
| ----------- | ------ |
| `ampersand` | `"&"`  |

### Vector Operators
These token types correspond to mathematical vector operations.

| Token Type  | Lexeme |
| ----------- | ------ |
| `dot_add`   | `".+"` |
| `dot_star`  | `".*"` |
| `dot_minus` | `".-"` |
| `dot_caret` | `".^"` |
| `at`        | `"@"`  |

### Matrix Operators
These token types correspond to matrix operations.

| Token Type   | Lexeme |
| ------------ | ------ |
| `star_plus`  | `"*+"` |
| `star_minus` | `"*-"` |
| `star_star`  | `"**"` |

### Literals
These token types correspond to literal values. The table below uses _Backus-Naur form_ for notation. Angle-bracketed terms correspond to expressions. These expressions are defined as follows:

- _`<digit>`_ : The digits ${0}$ through ${9.}$
- _`<letter>`_ : Symbols from the Latin alphabet, lower- and upper-case, (${a \ldots z}$ and ${A \ldots Z}$).
- _`<*>`_ : Any symbol. 

<table>
  <thead>
    <tr>
      <th>Token Type</th>
      <th>Lexeme</th>
      <th>Remark</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>`integer`</td>
      <td>(_`<1...9>`_ _`<digit>`_ `...` _`<digit>`_)</td>
      <td></td>
    </tr>
    <tr>
      <td>`float`</td>
      <td>_`<integer>`_ _`"."`_ _`<integer>`_</td>
      <td></td>
    </tr>
    <tr>
      <td>`fraction`</td>
      <td>_`<integer>`_ _`"/"`_ _`<integer>`_</td>
      <td></td>
    </tr>
    <tr>
      <td>`scientific`</td>
      <td>_`<float>`_ _`"E"`_ (_`"+"`_ | _`"-"`_) _`<integer>`_</td>
      <td></td>
    </tr>
    <tr>
      <td>`big_integer`</td>
      <td>_`"#"`_ _`<integer>`_</td>
      <td></td>
    </tr>
    <tr>
      <td>`symbol`</td>
      <td>(_`<letter>`_ ... _`<letter>`_)</td>
      <td>_The sequence cannot be a keyword or reserved word._</td>
    </tr>
    <tr>
      <td>`string`</td>
      <td>_`"`_ _`<*>`_ _`"`_</td>
      <td></td>
    </tr>
    <tr>
      <td>`boolean`</td>
      <td>(_`"true"`_ | _`"false"`_)</td>
      <td>_These are reserved words._</td>
    </tr>
    <tr>
      <td>`nan`</td>
      <td>_`"NaN"`_</td>
      <td>_This is a reserved word._</td>
    </tr>
    <tr>
      <td>`inf`</td>
      <td>_`"inf"`_</td>
      <td>_This is a reserved word._</td>
    </tr>
    <tr>
      <td>`nil`</td>
      <td>_`"nil"`_</td>
      <td>_This is a reserved word._</td>
    </tr>
    <tr>
      <td>`numeric_constant`</td>
      <td>(_`"e"`_ | _`"pi"`_)</td>
      <td>_This is a reserved word._</td>
    </tr>
  </tbody>
</table>

### Keywords
The following token types correspond to keywords in Rune.

| Token Type | Lexeme     |
| ---------- | ---------- |
| `and`      | `"and"`    |
| `or`       | `"or"`     |
| `not`      | `"not"`    |
| `nand`     | `"nand"`   |
| `xor`      | `"xor"`    |
| `xnor`     | `"xnor"`   |
| `nor`      | `"nor"`    |
| `if`       | `"if"`     |
| `else`     | `"else"`   |
| `fn`       | `"fn"`     |
| `let`      | `"let"`    |
| `var`      | `"var"`    |
| `return`   | `"return"` |
| `while`    | `"while"`  |
| `for`      | `"for"`    |
| `class`    | `"class"`  |
| `print`    | `"print"`  |
| `super`    | `"super"`  |
| `this`     | `"this"`   |
| `rem`      | `"rem"`    |
| `mod`      | `"mod"`    |
| `div`      | `"div"`    |

## Scanning
Now that we've listed all the possible tokens, we can begin writing the scanning procedure. In the source code, the scanning procedure is found in the _`lexical`_ function. This function takes a single argument, ${code,}$ of type _string_—this is the source code supplied by the user.

<Procedure>

1. __function__ ${lexical}$`(`${code}$: string`)`:
    1. __let__ ${line}$: ${\Z^+}$ = ${1}$
    2. __let__ ${start}$: ${\Z^+}$ = ${0}$
    3. __let__ ${current}$: ${\Z^+}$ = ${0}$
    4. __let__ ${error}$: ${\varnothing}$ | `ErrorObj` = ${\varnothing}$

</Procedure>

Immediately within this procedure, we initiate several mutable variables:

1. ${line}$ - A variable bound to a natural number, tracking which line we're looking at within the source code.
2. ${start}$ - Another natural number variable, tracking where we started.
3. ${current}$ - Another natural number variable, tracking where we currently are.
4. ${error}$ - A variable bound to either null or an `ErrorObj`, indicating whether an error's occurred.



export default function MDXPage({ children }) {
    return <MdxLayout>{children}</MdxLayout>
}